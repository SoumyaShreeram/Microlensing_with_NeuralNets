{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Neural_Network_Designs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCSvfRJyXetE1ZaHafhxi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaShreeram/Microlensing_with_NeuralNets/blob/master/04_Neural_Network_Designs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKLuj8uYka_K",
        "colab_type": "text"
      },
      "source": [
        "## Building the architectures for the Neural Networks\n",
        "\n",
        "The following script defines three different Neural Nets:\n",
        "1. **CNN1**: CNN without batch normalization\n",
        "2. **CNN2**: CNN with batch normalization\n",
        "2. **ResNet** \n",
        "\n",
        "Author: Soumya Shreeram\n",
        "Script adapted from: Millon Martin & Kevin MÃ¼ller\n",
        "Date: 16th March 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MkzBx35-Uto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import (Input, Dense, Conv1D, MaxPooling1D,\n",
        "                          Dropout, Flatten, BatchNormalization)\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xtGRanzkcLj",
        "colab_type": "text"
      },
      "source": [
        "### 2. Defines a modified pooling layer that outputs a 3D tenson\n",
        "\n",
        "Note: the `keras.layers.GLobalMaxPooling2D` returns a 2D tensor of shape: `(batch_size, channels)`. However, this pooling layer outputs a shape: `(batch_size, channels, rows or cols)` based on the input of data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XDuksc6kZiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalMaxPoolingSp2D(Layer):\n",
        "    \"\"\"Global max pooling operation for spatial data along a single dimension.\n",
        "    # Arguments\n",
        "        sqash_dim: A scalar\n",
        "            1: Find the maximum along the columns (the output doesn't the row dimension)\n",
        "            2: Find the maximum along the rows (the output doesn't the column dimension)\n",
        "            Defaults: squash_dim=2\n",
        "        data_format: A string,\n",
        "            one of `channels_last` (default) or `channels_first`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `channels_last` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `channels_first`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "    # Input shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, rows, cols, channels)`\n",
        "        - If `data_format='channels_first'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, channels, rows, cols)`\n",
        "    # Output shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            3D tensor with shape:\n",
        "            `(batch_size, rows or cols, channels)`\n",
        "        - If `data_format='channels_last'`:\n",
        "            3D tensor with shape:\n",
        "            `(batch_size, channels, rows or cols)`\n",
        "    \"\"\"\n",
        "    \n",
        "  \n",
        "    def __init__(self, squash_dim=2, data_format=None, **kwargs):\n",
        "        if data_format is None:\n",
        "          data_format = K.image_data_format()\n",
        "        data_format = data_format.lower()\n",
        "        if data_format not in {'channels_first', 'channels_last'}:\n",
        "          raise ValueError('The `data_format` argument must be one of '\n",
        "                           '\"channels_first\", \"channels_last\". Received: ' +\n",
        "                           str(value))\n",
        "        self.data_format = data_format\n",
        "        \n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "        self.squash_dim = squash_dim\n",
        "        super(GlobalMaxPoolingSp2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            return (input_shape[0], input_shape[3-self.squash_dim], input_shape[3])\n",
        "        else:\n",
        "            return (input_shape[0], input_shape[1], input_shape[4-self.squash_dim])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.data_format == 'channels_last':\n",
        "            return K.max(inputs, axis=self.squash_dim)\n",
        "        else:\n",
        "            return K.max(inputs, axis=self.squash_dim+1)\n",
        "      \n",
        "    def get_config(self):\n",
        "        config = {'data_format': self.data_format}\n",
        "        base_config = super(GlobalMaxPoolingSp2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvQLKL554N4Z",
        "colab_type": "text"
      },
      "source": [
        "General functions used to add:\n",
        "*   convolutional layers\n",
        "*   max pooling layers\n",
        "*   fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOU9eMMz1bAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addConvolutionalLayers(output, num_pix, num_filters, kernel_size, API=True):\n",
        "  \"\"\"\n",
        "  Function to add convolutional and max pooling layers to the model\n",
        "  @API :: boolean that decides wether to add layers sequenctially or using API\n",
        "  \"\"\"\n",
        "  if API:\n",
        "    kernel_size = (kernel_size, 1)\n",
        "    conv = Conv2D(num_filter, kernel_size, strides= (1,1),\\\n",
        "                      padding='same')(outputs) \n",
        "    outputs = Activation('relu')(conv)\n",
        "  # adds layers sequentially\n",
        "  else: \n",
        "    in_shape = (num_pix, None, 1) \n",
        "    kernel_size = (kernel_size, 1)\n",
        "    strides = (1,1)\n",
        "    # adds convolutional layers\n",
        "    output.add(Conv2D(num_filters, kernel_size, strides=strides, \\\n",
        "                    padding='same', input_shape = in_shape, activation='relu'))\n",
        "  return output\n",
        "\n",
        "def addPoolingLayers(output, maxpoolsize, API=True):\n",
        "  \"\"\"\n",
        "  Function adds pooling layers to the CNN\n",
        "  \"\"\"\n",
        "  if maxpoolsize is not None:\n",
        "    if API:\n",
        "      poolsize = (maxpoolsize,1)\n",
        "      output = MaxPooling2D(pool_size=poolsize, strides =(maxpoolsize,1))(output)       \n",
        "  else:\n",
        "      poolsize = (maxpoolsize,1)\n",
        "      output.add(MaxPooling2D(pool_size=poolsize, strides =(maxpoolsize,1)))       \n",
        "  return output\n",
        "\n",
        "def addFullyConnectedLayers(output, num_hidden_nodes, dropout_ratio, r_0,\\\n",
        "                            API=True):\n",
        "  \"\"\"\n",
        "  Function to add fully connected layers to the model\n",
        "  @num_hidden_nodes :: no. of nodes in the layers prior to the output layer\n",
        "  @dropout_ratio :: weight constrain in the dropout layers\n",
        "  @r_0 :: len(r_0) defines the no. of nodes in the output layer\n",
        "  \"\"\"\n",
        "  # post CNN; fully connected layers\n",
        "  for i, nodes in enumerate(num_hidden_nodes):\n",
        "    if API:\n",
        "      hidden = Dense(nodes, activation='sigmoid')(output)\n",
        "      activ = Activation('sigmoid')(hidden)\n",
        "      output = Dropout(dropout_ratio)(hidden)    \n",
        "    else:\n",
        "      output.add(Dense(nodes, activation='sigmoid'))\n",
        "      output.add(Dropout(dropout_ratio))\n",
        "  return output\n",
        "\n",
        "def printPlotModel(input_layers, output, filename):\n",
        "  model = Model(inputs=input_layers, outputs=output)\n",
        "  # summarize layers\n",
        "  print(model.summary())\n",
        "  # plot graph\n",
        "  plot_model(model, to_file=filename+'.png')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF-qfJPU_oPy",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Convolutional Neural Network: Design 1\n",
        "\n",
        "The following model used the `keras` Sequential models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsC1T9E2-anA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildModelCNN1(num_pix, num_filters, kernel_size, maxpoolsize,\\\n",
        "                   num_hidden_nodes, r_0):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @num_pix :: used to define the shape of the input layer\n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kernel_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden_nodes :: no. of nodes in the FNN layer right after the CNN\n",
        "  @r_0 :: array of all the scale radii\n",
        "  \n",
        "  @Returns:: model\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  \n",
        "  # adding convolutional and pooling layers\n",
        "  model = addConvolutionalLayers(model, num_pix, num_filters, kernel_size, API=False)\n",
        "  model = addPoolingLayers(model, maxpoolsize, API=False)\n",
        "  model.add(GlobalMaxPoolingSp2D())\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  model = addFullyConnectedLayers(model, num_pix, num_hidden_nodes,\\\n",
        "                                  dropout_ratio, r_0, API=False)\n",
        "  # final output layer\n",
        "  model.add(Dense(len(r_0), activation='softmax'))\n",
        "\n",
        "  # summarize the layers\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KkJ44kC_Eh",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Convolutional Neural Network: Design 2\n",
        "\n",
        "This CNN accounts for batch normalization unlike the first case. Additionally, used Keras functional API for more flexibitity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCUBWA6OC-yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def builfModelCNN2(num_filter, kern_size, maxpoolsize, num_hidden, \\\n",
        "                   dropout_ratio, shortcut, batch_norm, length_traj):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kernel_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden_nodes :: no. of nodes in the FNN layer right after the CNN\n",
        "  @dropout_ratio :: weight constrain on the dropout layer of the FNN \n",
        "  @shortcut :: arr that decides when to take the skip connections/shortcuts\n",
        "  @bath_norm :: bool decided wether or not to normalize the output from a layer\n",
        "  @r_0 :: array of all the scale radii\n",
        "  \n",
        "  @Returns:: model output\n",
        "  \"\"\"\n",
        "  #input layer\n",
        "  visible = Input(shape=(length_traj, None, 1))\n",
        "  output = visible\n",
        "\n",
        "  # skip connection variables\n",
        "  execute_skip = False\n",
        "  idx = 0\n",
        "\n",
        "  for i in range(len(num_filter)):\n",
        "    # shortcut path/ skip connection\n",
        "    if shortcut and not execute_skip and shortcut[idx] == i:\n",
        "      out_shortcut = output\n",
        "      execute_skip = True\n",
        "      idx += 1\n",
        "    \n",
        "    # feature extractors\n",
        "    conv = addConvolutionalLayers(output, num_pix, num_filters, kernel_size[i],\\\n",
        "                                  API=True)\n",
        "    # batch normalization, activation\n",
        "    if batch_norm: \n",
        "      conv = BatchNormalization()(conv)  \n",
        "    conv = Activation('selu')(conv)\n",
        "\n",
        "    # execute skip connection\n",
        "    if shortcut and execute_skip and shortcut[idx] == i:\n",
        "      conv = concatenate(3)([conv, out_shortcut])\n",
        "      execute_skip = False\n",
        "      idx += 1\n",
        "\n",
        "    # adds max pooling layers\n",
        "    conv = addPoolingLayers(conv, maxpoolsize[i], API=True)\n",
        "    \n",
        "  pool = GlobalMaxPoolingSp2D()(conv)\n",
        "  flat = Flatten()(pool)\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  hidden = addFullyConnectedLayers(flat, num_hidden_nodes, dropout_ratio, r_0, \\\n",
        "                                  API=True)\n",
        "  output = Dense(len(r_0))(hidden)\n",
        "  output = Activation('hidden')(output)\n",
        "\n",
        "  model = printPlotModel(visible, output, 'Images/CNN2')\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMvRFfuH_ekY",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Residual neural network: ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtgQSEE5_Uy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "ce6c86d8-3258-4c1f-90c1-37fbe1684f22"
      },
      "source": [
        "def buildModelResNet(num_pix, num_filter, kern_size, n_block, maxpoolsize, num_hidden, \\\n",
        "                dropout_ratio, batch_norm):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @num_pix :: used to define the shape of the input layer\n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kern_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @n_block :: int decides the no. of conv layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden :: no. of nodes in the fully connected layer right after the CNN\n",
        "  @dropout_ratio :: weight constrain on the dropout layer of the FNN \n",
        "  @bath_norm :: bool decided wether or not to normalize the output from a layer\n",
        "  @r_0 :: array of all the scale radii\n",
        "  \n",
        "  @Returns:: model output\n",
        "  \"\"\"\n",
        "  visible = Input(shape=(num_pix, None, 1))\n",
        "  shortcut = visible\n",
        "\n",
        "  for i in range(n_block):\n",
        "    # adding convolutional layers\n",
        "    conv = addConvolutionalLayers(output, num_pix, num_filters, kernel_size[i],\\\n",
        "                                    API=True)\n",
        "    conv = Add()[conv,shortcut]\n",
        "\n",
        "    # adds max pooling and normalizes the layer\n",
        "    conv = addPoolingLayers(conv, maxpoolsize[i], API=True)\n",
        "    if batch_norm: \n",
        "      conv = BatchNormalization()(conv)\n",
        "\n",
        "    # skip connection redefined\n",
        "    shortcut = conv\n",
        "\n",
        "  pool = GlobalMaxPoolingSp2D()(conv)\n",
        "  flat = Flatten()(pool)\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  hidden = addFullyConnectedLayers(flat, num_hidden_nodes, dropout_ratio, r_0, \\\n",
        "                                  API=True)\n",
        "  output = Dense(len(r_0))(hidden)\n",
        "  output = Activation('softmax')(output)\n",
        "  \n",
        "  model, printPlotModel(visible, output, 'Images/ResNet')\n",
        "  return model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-6f11f273ff05>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def buildModelResNet(num_pix, num_filter, kern_size, n_block, maxpoolsize, num_hidden,                 dropout_ratio, batch_norm = True, optim):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vcFOrvNVz3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}