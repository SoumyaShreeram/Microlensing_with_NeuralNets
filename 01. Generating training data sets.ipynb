{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generation of light-curves for training NNs\n",
        "\n",
        "The scripts is used to generate data sets containing light curves for training neural networks. The script contains:\n",
        "\n",
        "1. Paths to directories and Input parameters\n",
        "2. Extracting data from microlensing light-curves\n",
        "3. Creating mock light-curves fpr a given magnification map and velocity\n",
        "4. Storing the generated light curves \n",
        "\n",
        "Rewritten by: Soumya Shreeram <br>\n",
        "Script adapted from: Eric Paic <br>\n",
        "Date: 02nd March 2020"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os,sys\n",
        "import pickle as pkl\n",
        "from astropy.io import fits\n",
        "import glob"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-03-02T10:29:22.148Z",
          "iopub.execute_input": "2020-03-02T10:29:22.152Z",
          "shell.execute_reply": "2020-03-02T10:29:22.162Z",
          "iopub.status.idle": "2020-03-02T10:29:22.159Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Paths to directories and Input parameters"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "root_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
        "data_dir = os.path.join(root_dir)\n",
        "print(\"Does directory exists? \\n>\",os.path.isdir(data_dir))\n",
        "\n",
        "# setting the paths\n",
        "datadir = data_dir + '/Data/'\n",
        "scriptdir = data_dir + '/Data/scripts'\n",
        "resultdir = data_dir + '/Data/results'\n",
        "mapdir = data_dir + '/Data/maps/unconvolved/'\n",
        "storagedir = data_dir + '/Data/maps/storage/'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does directory exists? \n",
            "> True\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-03-02T10:34:27.362Z",
          "iopub.execute_input": "2020-03-02T10:34:27.364Z",
          "iopub.status.idle": "2020-03-02T10:34:27.369Z",
          "shell.execute_reply": "2020-03-02T10:34:27.372Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants used to convert pixels to physical length"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "einstein_r_1131= 2.5e16 #Einstein ring of RXJ1131 in cm assuming <M> = 0.3 M_0\n",
        "einstein_r_03 = 3.414e16 #Einstein ring of QJ0158 in cm assuming <M> = 0.3 M_0\n",
        "einstein_r_01 = einstein_r_03/np.sqrt(3) #Einstein ring of QJ0158 in cm assuming <M> = 0.1 M_0\n",
        "einstein_r_001 = einstein_r_03/np.sqrt(30) #Einstein ring of QJ0158 in cm assuming <M> = 0.01 M_0\n",
        "\n",
        "cm_per_pxl = 20*einstein_r_03/8192 #Find pixel scale assuming the map is 20R_E x 20R_E and 8192 pxl x 8192pxl\n",
        "ld_per_pxl = cm_per_pxl/(30000000000*3600*24) #Light-day per pixel"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Extracting the data microlensing light curve"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def good_draw_LC(params, map, time, cm_per_pxl , err_data, add_shut_noise=0):\n",
        "    \"\"\"\n",
        "    Function to draw a light curve in a microlensing map\n",
        "    @params:: is a list composed with the starting coordinaates of the trajectory, its velocity and direction.\n",
        "    @map:: is the map used to draw the curve\n",
        "    @time:: decides the sampling of the microlensing curve\n",
        "    @cm_per_pxl:: gives the scale of the map which is calculated by knowing that a map is 20 R_e x 20 R_e\n",
        "    @ err_data:: may be used to add experimental shutnoise to the resulting lightcurve if add_shut_noise=1\n",
        "\n",
        "    @Returns the generated light curve and the coordinates of the starting and ending point of the trajectory, the latter is used only to display the trajectory.\n",
        "    \"\"\"    \n",
        "    x_start = params[0]\n",
        "    y_start = params[1]\n",
        "    v = params[2]\n",
        "    angle= params[3]\n",
        "\n",
        "\n",
        "    #Projecting the velocity on x and y axis\n",
        "    v_x = np.multiply(v, np.cos(angle))\n",
        "    v_x = np.divide(np.multiply(100000 * 3600 * 24, v_x), cm_per_pxl)\n",
        "    v_y = np.multiply(v, np.sin(angle))\n",
        "    v_y = np.divide(np.multiply(100000 * 3600 * 24, v_y), cm_per_pxl)\n",
        "\n",
        "    #Calculating the trajectory of the source in the map\n",
        "    if v_x == 0:\n",
        "        path_x = x_start * np.ones(len(time))\n",
        "    else:\n",
        "        path_x = np.add(np.multiply(np.add(time, -time[0]), v_x), x_start)\n",
        "    if v_y == 0:\n",
        "        path_y = y_start * np.ones(len(mjhd))\n",
        "    else:\n",
        "        path_y = np.add(np.multiply(np.add(time, -time[0]), v_y), y_start)\n",
        "\n",
        "    path_x = path_x.astype(int)\n",
        "    path_y = path_y.astype(int)\n",
        "\n",
        "    # Checking if the trajectory doesn't go out of the map and gathering the value of the corresponding pixels which give the flux magnification (Hence 2.5*log() to convert in mag).\n",
        "    if path_x[-1] <= len(map)-1 and path_y[-1] <= len(map)-1 and path_x[-1] >= 0 and path_y[-1] >= 0:\n",
        "        if add_shut_noise:\n",
        "            temp = np.add(np.multiply(-2.5, np.log10(map[path_y, path_x])),np.random.normal(0, np.mean(err_data), len(path_y)))\n",
        "        else:\n",
        "            temp = np.multiply(-2.5, np.log10(map[path_y, path_x]))\n",
        "        lc = temp - temp[0] * np.ones(len(temp))\n",
        "        return lc, [path_x[0], path_y[0], path_x[-1], path_y[-1]]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading from the file and getting the info"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(datadir+\"/microlensing/data/J0158_Euler_microlensing_upsampled_B-A.rdb\",\"r\")\n",
        "\n",
        "f= f.read()\n",
        "f=f.split(\"\\n\")\n",
        "data = f[2:]\n",
        "\n",
        "mjhd = np.array([]) # Time\n",
        "mag_ml = np.array([]) # Magnitude of microlensing\n",
        "err_mag_ml = np.array([]) # Error on the magnitude\n",
        "\n",
        "for i,elem in enumerate(data):\n",
        "    mjhd = np.append(mjhd,float(elem.split(\"\\t\")[0]))\n",
        "    mag_ml = np.append(mag_ml, float(elem.split(\"\\t\")[1]))\n",
        "    temp = elem.split(\"\\t\")[2]\n",
        "    err_mag_ml= np.append(err_mag_ml,float(temp.split(\"\\r\")[0]))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Creating mock light-curves for a given magnification map and velocity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_r0 = [2,4,10,15,20,30,40,60,80,100] #radii of the source in pxl, the reference radius is 15pxl\n",
        "n_curves = 100000 #number of generated curves\n",
        "n_good_curves = 5000 #minimum number of curves that are not flat\n",
        "for r0 in list_r0:\n",
        "    print r0\n",
        "    map = storagedir + \"FML0.9/M0,3/mapA-B_fml09_R%s.fits\" % (r0) #path to the magnification map\n",
        "    img = fits.open(map)[0]\n",
        "    final_map = img.data[:, :]\n",
        "    v_source =500 #in km.s^-1\n",
        "    v = v_source * np.ones(n_curves)\n",
        "\n",
        "    # generating random starting coordinates and angles of the trajectories\n",
        "    x = np.random.random_integers(200, len(final_map) - 200, n_curves)\n",
        "    y = np.random.random_integers(200, len(final_map) - 200, n_curves)\n",
        "    angle = np.random.uniform(0, 2 * np.pi, n_curves)\n",
        "\n",
        "    params = []\n",
        "    for i, elem in enumerate(x):\n",
        "        params.append([x[i], y[i], v[i], angle[i]])\n",
        "\n",
        "    lc = []\n",
        "    i = 0\n",
        "    j=0\n",
        "    while i<n_good_curves:\n",
        "        # Here mjhd is the time vector extracted form the data so if you use it to generate mock curves they will already have the season gaps.\n",
        "        temp= good_draw_LC(params[j], final_map,mjhd, err_mag_ml,(20 * einstein_r_03) / 8192)\n",
        "        j += 1\n",
        "        if temp is not None:\n",
        "            temp = temp[0]\n",
        "            if np.amax(temp)-np.amin(temp) > 1: # we consider a curve is \"not flat\" if the difference between it min and max is over 1\n",
        "                lc.append(temp)\n",
        "                i+=1\n",
        "                if i%1000 ==0:\n",
        "                    print i"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Storing light-curves in a pkl file"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(resultdir + 'LCmocks/simLC_A-B_n%s_v%s_R%s_M0,3.pkl' % (\n",
        "     n_good_curves, v_source, r0), 'wb') as handle:\n",
        "        pkl.dump((lc), handle, protocol=pkl.HIGHEST_PROTOCOL)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "argv": [
        "python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "nteract": {
      "version": "0.22.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}