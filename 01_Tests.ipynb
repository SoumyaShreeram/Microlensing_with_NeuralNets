{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Tests.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP9Z+4eH4ebBdVsznug/p5x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaShreeram/Microlensing_with_NeuralNets/blob/master/01_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv0iBoEj6qK3",
        "colab_type": "text"
      },
      "source": [
        "## Testing Neural Network Architecture\n",
        "\n",
        "Author: Soumya Shreeram <br>\n",
        "Script adapted from: Millon Martin & Kevin MÃ¼ller <br>\n",
        "Date: 23rd February 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deDcrZnEPlzz",
        "colab_type": "text"
      },
      "source": [
        "Import all required python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIOkLVF5WNgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Activation, InputSpec\n",
        "from tensorflow.python.keras.layers import Conv1D, Conv2D\n",
        "from tensorflow.python.keras.layers import MaxPooling1D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Add, BatchNormalization, Concatenate\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDf-kPS_OvVQ",
        "colab_type": "text"
      },
      "source": [
        "Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7aoHjFTP2s9",
        "colab_type": "code",
        "outputId": "8d8c56c2-da4c-4bea-fa92-039924564489",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJbzcl4A8xJQ",
        "colab_type": "text"
      },
      "source": [
        "Setting up the path to the data directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3kJxIDwwxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "current_dir = os.getcwd()\n",
        "data_dir = os.path.join(current_dir, '/gdrive/My Drive/EPFL/training_set_microlensing/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF4SshagaAw2",
        "colab_type": "text"
      },
      "source": [
        "### 1. Input parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQFOUe7Z-98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v_t = [500, 300] # transverse velcity\n",
        "v_t_idx = 1 # choose index value for the velocity you would like (0 or 1)\n",
        "r_0 = [2,4,10,15,20,30,40,60,80,100] # scale radius"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFkVx1DI8dE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setSamplingParameters(v_t, euler_sampling, data_dir):\n",
        "  \"\"\"\n",
        "  Function defines the values for sampling parameters and no. of pixels \n",
        "\n",
        "  Inputs:\n",
        "  @v_t :: transverse velocity\n",
        "  @euler_sampling :: sampling of real data taken by the Euler telescope\n",
        "  @data_dir :: directory with the model light-curves for inputted v_t\n",
        "\n",
        "  Retutns:\n",
        "  @n_sample, n_sample_max :: ...\n",
        "  @n_pix :: ...\n",
        "  \"\"\"\n",
        "  if v_t == 500:\n",
        "    if euler_sampling: \n",
        "      n_sample, n_sample_max, n_pix = 5000, 5000, 4546\n",
        "    else:\n",
        "      n_sample, n_sample_max, n_pix = 5000, 5000, 486\n",
        "\n",
        "  else:\n",
        "    n_sample, n_sample_max, n_pix = 20000, 3000, 1137\n",
        "    sample_params = [n_sample, n_sample_max, n_pix]\n",
        "  return sample_params\n",
        "\n",
        "def initializer(r_0, sample_params):\n",
        "  \"\"\"\n",
        "  Function defines the class names, categories, and initializes the data arrays\n",
        "  Input:\n",
        "  @r_0 :: arr with all the scale radii of the background quasar\n",
        "  @sample_params :: arr containing values for sampling frequency \n",
        "  \"\"\"\n",
        "  # generate categories and class names \n",
        "  classes = np.array(map(str, r_0))\n",
        "  categories = np.arange(len(r_0))\n",
        "\n",
        "  # initialize data arrays to be classified\n",
        "  in_data = np.zeros(sample_params[0]*len(r_0), sample_params[2], 1)\n",
        "  out_catergories, out_radii = np.zeros(sample_params[0]*len(r_0))\n",
        "  \n",
        "  return in_data, out_catergories, out_radii\n",
        "\n",
        "def getFilename(data_dir, r, v_t[v_t_idx]):\n",
        "  if v == v_t[v_t_idx]:\n",
        "    filename = data_dir + 'simLC_A-B_n20000_v300_R' + str(r)  + '_M0,3.pkl'\n",
        "  else:\n",
        "    filename = data_dir + 'simLC_A-B_n50000_v500_R' + str(r)  + '_M0,3.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwCb_eMa9AlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sets the sampling parameters\n",
        "sample_params = setSamplingParameters(v_t[v_t_idx], euler_sampling, data_dir)\n",
        "\n",
        "# initializes data arrays\n",
        "in_data, out_catergories, out_radii = initializer(r_0, sample_params)\n",
        "\n",
        "for r in range(len(r_0)):\n",
        "  filename = getFilename(data_dir, r, v_t[v_t_idx])\n",
        "  \n",
        "  # load data from the file\n",
        "  in_data, out_catergories, out_radii = loadData(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}