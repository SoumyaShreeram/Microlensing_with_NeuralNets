{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Neural_Network_Designs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO68y6o+ZPdIhQ57FymHn50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SoumyaShreeram/Microlensing_with_NeuralNets/blob/master/04_Neural_Network_Designs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKLuj8uYka_K",
        "colab_type": "text"
      },
      "source": [
        "## Building the architectures for the Neural Networks\n",
        "\n",
        "The following script defines three different Neural Nets:\n",
        "1. **CNN1**: CNN without batch normalization\n",
        "2. **CNN2**: CNN with batch normalization\n",
        "2. **ResNet** \n",
        "\n",
        "Author: Soumya Shreeram\n",
        "Script adapted from: Millon Martin & Kevin MÃ¼ller\n",
        "Date: 16th March 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MkzBx35-Uto",
        "colab_type": "code",
        "outputId": "a69f581a-fbf5-47d6-ff75-027eb6ef39a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from IPython.display import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import (Input, Dense, Conv1D, MaxPooling1D,\n",
        "                          Dropout, Flatten, BatchNormalization)\n",
        "from keras import optimizers\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xtGRanzkcLj",
        "colab_type": "text"
      },
      "source": [
        "### 2. Defines a modified pooling layer that outputs a 3D tenson\n",
        "\n",
        "Note: the `keras.layers.GLobalMaxPooling2D` returns a 2D tensor of shape: `(batch_size, channels)`. However, this pooling layer outputs a shape: `(batch_size, channels, rows or cols)` based on the input of data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XDuksc6kZiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GlobalMaxPoolingSp2D(Layer):\n",
        "    \"\"\"Global max pooling operation for spatial data along a single dimension.\n",
        "    # Arguments\n",
        "        sqash_dim: A scalar\n",
        "            1: Find the maximum along the columns (the output doesn't the row dimension)\n",
        "            2: Find the maximum along the rows (the output doesn't the column dimension)\n",
        "            Defaults: squash_dim=2\n",
        "        data_format: A string,\n",
        "            one of `channels_last` (default) or `channels_first`.\n",
        "            The ordering of the dimensions in the inputs.\n",
        "            `channels_last` corresponds to inputs with shape\n",
        "            `(batch, height, width, channels)` while `channels_first`\n",
        "            corresponds to inputs with shape\n",
        "            `(batch, channels, height, width)`.\n",
        "            It defaults to the `image_data_format` value found in your\n",
        "            Keras config file at `~/.keras/keras.json`.\n",
        "            If you never set it, then it will be \"channels_last\".\n",
        "    # Input shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, rows, cols, channels)`\n",
        "        - If `data_format='channels_first'`:\n",
        "            4D tensor with shape:\n",
        "            `(batch_size, channels, rows, cols)`\n",
        "    # Output shape\n",
        "        - If `data_format='channels_last'`:\n",
        "            3D tensor with shape:\n",
        "            `(batch_size, rows or cols, channels)`\n",
        "        - If `data_format='channels_last'`:\n",
        "            3D tensor with shape:\n",
        "            `(batch_size, channels, rows or cols)`\n",
        "    \"\"\"\n",
        "    \n",
        "  \n",
        "    def __init__(self, squash_dim=2, data_format=None, **kwargs):\n",
        "        if data_format is None:\n",
        "          data_format = K.image_data_format()\n",
        "        data_format = data_format.lower()\n",
        "        if data_format not in {'channels_first', 'channels_last'}:\n",
        "          raise ValueError('The `data_format` argument must be one of '\n",
        "                           '\"channels_first\", \"channels_last\". Received: ' +\n",
        "                           str(value))\n",
        "        self.data_format = data_format\n",
        "        \n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "        self.squash_dim = squash_dim\n",
        "        super(GlobalMaxPoolingSp2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.data_format == 'channels_last':\n",
        "            return (input_shape[0], input_shape[3-self.squash_dim], input_shape[3])\n",
        "        else:\n",
        "            return (input_shape[0], input_shape[1], input_shape[4-self.squash_dim])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.data_format == 'channels_last':\n",
        "            return K.max(inputs, axis=self.squash_dim)\n",
        "        else:\n",
        "            return K.max(inputs, axis=self.squash_dim+1)\n",
        "      \n",
        "    def get_config(self):\n",
        "        config = {'data_format': self.data_format}\n",
        "        base_config = super(GlobalMaxPoolingSp2D, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvQLKL554N4Z",
        "colab_type": "text"
      },
      "source": [
        "General functions used to add:\n",
        "*   convolutional layers\n",
        "*   max pooling layers\n",
        "*   fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOU9eMMz1bAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addConvPoolingLayers(model, num_pix, num_filters, kernel_size, maxpoolsize):\n",
        "  \"\"\"\n",
        "  Function to add convolutional and max pooling layers to the model\n",
        "  \"\"\"\n",
        "  in_shape = (num_pix, None, 1) \n",
        "  kernel_size = (kernel_size, 1)\n",
        "  strides = (1,1)\n",
        "  # adds convolutional layers\n",
        "  model.add(Conv2D(num_filters, kernel_size, strides=strides, \\\n",
        "                  padding='same', input_shape = in_shape, activation='relu'))\n",
        "        \n",
        "  # adds pooling layers\n",
        "  if maxpoolsize is not None:\n",
        "    poolsize = (maxpoolsize,1)\n",
        "    model.add(MaxPooling2D(pool_size=poolsize, strides =(maxpoolsize,1)))\n",
        "  return model\n",
        "\n",
        "def addFullyConnectedLayers(model, num_hidden_nodes, dropout_ratio, r_0):\n",
        "  \"\"\"\n",
        "  Function to add fully connected layers to the model\n",
        "  @num_hidden_nodes :: no. of nodes in the layers prior to the output layer\n",
        "  @dropout_ratio :: weight constrain in the dropout layers\n",
        "  @r_0 :: len(r_0) defines the no. of nodes in the output layer\n",
        "  \"\"\"\n",
        "  # post CNN; fully connected layers\n",
        "  for i, nodes in enumerate(num_hidden_nodes):\n",
        "    model.add(Dense(nodes, activation='sigmoid'))\n",
        "    model.add(Dropout(dropout_ratio))\n",
        "\n",
        "  # final output layer\n",
        "  model.add(Dense(len(r_0), activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF-qfJPU_oPy",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Convolutional Neural Network: Design 1\n",
        "\n",
        "The following model used the `keras` Sequential models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsC1T9E2-anA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildModelCNN1(num_pix, num_filters, kernel_size, maxpoolsize, num_hidden_nodes,\\\n",
        "              r_0, optim):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @num_pix :: used to define the shape of the input layer\n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kernel_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden_nodes :: no. of nodes in the FNN layer right after the CNN\n",
        "  @r_0 :: array of all the scale radii\n",
        "  @opt :: optimizer-type for the Neural Net\n",
        "\n",
        "  @Returns:: model\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  \n",
        "  # adding convolutional and pooling layers\n",
        "  model = addConvPoolingLayers(model, num_pix, num_filters, kernel_size, maxpoolsize)\n",
        "  model.add(GlobalMaxPoolingSp2D())\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  model = addFullyConnectedLayers(model, num_pix, num_hidden_nodes, dropout_ratio, r_0)\n",
        "\n",
        "  # optimizer \n",
        "  sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
        "\n",
        "  # compilation for a multi-category classification problem\n",
        "  model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KkJ44kC_Eh",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Convolutional Neural Network: Design 2\n",
        "\n",
        "This CNN accounts for batch normalization unlike the first case. Additionally, used Keras functional API for more flexibitity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCUBWA6OC-yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def builfModelCNN2(num_filter, kern_size, maxpoolsize, num_hidden, \\\n",
        "                   dropout_ratio, shortcut_link, batch_norm, length_traj):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @length_traj :: used to define the shape of the input layer\n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kernel_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden_nodes :: no. of nodes in the FNN layer right after the CNN\n",
        "  @r_0 :: array of all the scale radii\n",
        "  @opt :: optimizer-type for the Neural Net\n",
        "\n",
        "  @Returns:: model\n",
        "  \"\"\"\n",
        "  visible = Input(shape=(length_traj, None, 1))\n",
        "  \n",
        "  # adding convolutional and pooling layers\n",
        "  for i in range(len(num_filter)):\n",
        "    kernel_size = (kernel_size[i], 1)\n",
        "    strides = (1,1)\n",
        "    hidden1 = Conv2D(num_filters, kernel_size, strides=strides, padding='same',\n",
        "                     activation='relu')(visible)\n",
        "\n",
        "    # batch normalization (nomalizes the inputted layer)\n",
        "    hidden1 = BatchNormalization()(hidden1)  \n",
        "    hidden1 = Activation('selu')(hidden1)\n",
        "    \n",
        "    #              \n",
        "  model.add(GlobalMaxPoolingSp2D())\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  model = addFullyConnectedLayers(model, num_hidden_nodes, dropout_ratio, r_0)\n",
        "\n",
        "  # optimizer \n",
        "  sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
        "\n",
        "  # compilation for a multi-category classification problem\n",
        "  model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMvRFfuH_ekY",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Residual neural network: ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtgQSEE5_Uy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildModelResNet(num_filter, kern_size, n_block, maxpoolsize, num_hidden, \\\n",
        "                dropout_ratio, batch_norm = True, optim):\n",
        "  \"\"\"\n",
        "  Function to build the model architecture, set optimizers and compile the model \n",
        "  @num_pix :: used to define the shape of the input layer\n",
        "  @num_filters :: arr with the ascending order of filters in the conv2D layers\n",
        "  @kernel_size :: arr with the kernel sizes for the corresponding conv2D layers\n",
        "  @maxpoolsize :: arr with the pool sizes for the corresponding conv2D layers\n",
        "  @num_hidden_nodes :: no. of nodes in the FNN layer right after the CNN\n",
        "  @dropout_ratio :: weight constrain on the dropout layer of the FNN \n",
        "  @r_0 :: array of all the scale radii\n",
        "  @opt :: optimizer-type for the Neural Net\n",
        "\n",
        "  @Returns:: model\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(AveragePooling1D(pool_size=5))\n",
        "  \n",
        "  # adding convolutional and pooling layers\n",
        "  model = addConvPoolingLayers(model, num_filters, kernel_size, maxpoolsize)\n",
        "  # some output shortcut trickery\n",
        "\n",
        "  if batch_norm: \n",
        "    model.add(layers.BatchNormalization())\n",
        "  model.add(GlobalMaxPoolingSp2D())\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  # fully connected layers; added dropout these layer with weight constraint\n",
        "  model = addFullyConnectedLayers(model, num_hidden_nodes, dropout_ratio, r_0)\n",
        "\n",
        "  # optimizer \n",
        "  sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=False)\n",
        "\n",
        "  # compilation for a multi-category classification problem\n",
        "  model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}